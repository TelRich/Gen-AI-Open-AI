{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting started with Natural Language Processing (NLP) often begins with understanding fundamental concepts and techniques, and one of the simplest and widely used methods is the \"Bag of Words\" (BoW) model. BoW represents text data as a collection of words without considering the order or structure. Below is a brief explanation of BoW and some practical Python examples to help you get started.\n",
    "\n",
    "### Bag of Words (BoW) Overview\n",
    "\n",
    "The Bag of Words model is a text representation technique that converts a document (such as a sentence or a paragraph) into a set of individual words. It discards grammar, word order, and focuses solely on the frequency of words in the text. The idea is to create a vocabulary of words present in the text and count how many times each word appears in the document.\n",
    "\n",
    "### Practical Examples\n",
    "\n",
    "#### 1. Creating a BoW Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with their index in the model:\n",
      "{'this': 14, 'is': 8, 'sample': 12, 'example': 6, 'of': 10, 'bow': 2, 'in': 7, 'nlp': 9, 'bag': 0, 'words': 15, 'basic': 1, 'technique': 13, 'you': 16, 'can': 3, 'create': 4, 'representation': 11, 'easily': 5}\n",
      "\n",
      "\n",
      "BOW Representation:\n",
      "[[0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 0 0]\n",
      " [1 1 0 0 0 0 0 1 1 1 1 0 0 1 0 1 0]\n",
      " [0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 1]]\n",
      "\n",
      "\n",
      "Vocabulary:\n",
      "['bag' 'basic' 'bow' 'can' 'create' 'easily' 'example' 'in' 'is' 'nlp'\n",
      " 'of' 'representation' 'sample' 'technique' 'this' 'words' 'you']\n"
     ]
    }
   ],
   "source": [
    "# This line imports the CountVectorizer from scikit-learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample Document\n",
    "\n",
    "documents = [\n",
    "    \"This is a sample example of BOW.\",\n",
    "    \"In NLP, Bag of Words is a basic technique.\",\n",
    "    'You can create a BOW representation easily.'\n",
    "]\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the documents\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert the result to a dense array for readability\n",
    "bow_array = X.toarray()\n",
    "# Get the vocabulary\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Print the BOW representation and vocabulary\n",
    "print(\"Words with their index in the model:\")\n",
    "print(vectorizer.vocabulary_)\n",
    "print('\\n')\n",
    "print(\"BOW Representation:\")\n",
    "print(bow_array)\n",
    "print('\\n')\n",
    "print(\"Vocabulary:\")\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we use the `CountVectorizer` from the scikit-learn library to create a BoW representation of the sample documents. The resulting `bow_array` contains the word frequencies, and `vocabulary` stores the list of words, as seen above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Transform New Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Representation of New Text:\n",
      "[[0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "new_text = [\"This is a new text for testing.\"]\n",
    "\n",
    "# Transform the new text using the same vectorizer\n",
    "new_text_bow = vectorizer.transform(new_text)\n",
    "\n",
    "# Convert to a dense array and print\n",
    "new_text_array = new_text_bow.toarray()\n",
    "print(\"BoW Representation of New Text:\")\n",
    "print(new_text_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code demostrates how to transform a new text using the same vectorizer to create its BoW representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Handling Stop Words\n",
    "\n",
    "To improve BoW, you can remove common words like \"the,\" \"is,\" and \"a\" (stop words) that don't carry much information. You can specify a custom stop words list while initializing the `CountVectorizer`:\n",
    "\n",
    "```python\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Custom list of stop words\n",
    "custom_stop_words = [\"this\", \"is\", \"a\", \"of\", \"in\", \"you\", \"can\"]\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=custom_stop_words)\n",
    "# Continue as before\n",
    "```\n",
    "\n",
    "These are basic examples to get you started with the Bag of Words model in NLP. From here, you can explore more advanced techniques like TF-IDF, N-grams, and various machine learning algorithms to work with text data effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words with their index in the model:\n",
      "{'sample': 8, 'example': 5, 'bow': 2, 'nlp': 6, 'bag': 0, 'words': 10, 'basic': 1, 'technique': 9, 'create': 3, 'representation': 7, 'easily': 4}\n",
      "\n",
      "\n",
      "BOW Representation:\n",
      "[[0 0 1 0 0 1 0 0 1 0 0]\n",
      " [1 1 0 0 0 0 1 0 0 1 1]\n",
      " [0 0 1 1 1 0 0 1 0 0 0]]\n",
      "\n",
      "\n",
      "Vocabulary:\n",
      "['bag' 'basic' 'bow' 'create' 'easily' 'example' 'nlp' 'representation'\n",
      " 'sample' 'technique' 'words']\n"
     ]
    }
   ],
   "source": [
    "# Custom list of stop words\n",
    "custom_stop_words = [\"this\", \"is\", \"a\", \"of\", \"in\", \"you\", \"can\"]\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer(stop_words=custom_stop_words)\n",
    "\n",
    "# Fit and transform the documents\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# COnvert the results to a dense array for readability\n",
    "bow_array = X.toarray()\n",
    "\n",
    "# Get the Vocabulary \n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Print the BOW representation and vocabulary\n",
    "print(\"Words with their index in the model:\")\n",
    "print(vectorizer.vocabulary_)\n",
    "print('\\n')\n",
    "print(\"BOW Representation:\")\n",
    "print(bow_array)\n",
    "print('\\n')\n",
    "print(\"Vocabulary:\")\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermediate BoW Examples\n",
    "\n",
    "let's dive into more intermediate examples of using the Bag of Words (BoW) model in Natural Language Processing (NLP). In these examples, we'll explore some advanced techniques and applications.\n",
    "\n",
    "#### 1. BoW with Tokenization and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Representation:\n",
      "[[0 0 1 0 0 0 1 0 1 0 1 0 1 0 1 0 0]\n",
      " [1 1 0 0 0 0 0 1 1 1 1 0 0 1 0 1 0]\n",
      " [0 0 1 1 1 1 0 0 0 0 0 1 0 0 0 0 1]]\n",
      "\n",
      "\n",
      "Vocabulary:\n",
      "['bag' 'basic' 'bow' 'can' 'create' 'easily' 'example' 'in' 'is' 'nlp'\n",
      " 'of' 'representation' 'simple' 'technique' 'this' 'words' 'you']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample documents\n",
    "documents = [\"This is a simple example of BoW.\",\n",
    "             \"In NLP, Bag of Words is a basic technique.\",\n",
    "             \"You can create a BoW representation easily.\"]\n",
    "\n",
    "# Tokenization and preprocessing\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "documents = [' '.join(word_tokenize(doc.lower())) for doc in documents]\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the documents\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to a dense array for readability\n",
    "bow_array = X.toarray()\n",
    "\n",
    "# Get the vocabulary\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"BoW Representation:\")\n",
    "print(bow_array)\n",
    "print('\\n')\n",
    "print(\"Vocabulary:\")\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we tokenize the text using NLTK's `word_tokenize` and convert it to lowercase before creating the BoW representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. BoW with Bigrams (Word Pairs)\n",
    "\n",
    "In BoW, you can use bigrams to capture word pairs, not just individual words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW Representation with Bigrams:\n",
      "[[0 0 0 0 0 1 0 0 1 0 1 0 0 1 1 0 0]\n",
      " [1 1 0 0 0 0 1 1 0 1 0 1 0 0 0 1 0]\n",
      " [0 0 1 1 1 0 0 0 0 0 0 0 1 0 0 0 1]]\n",
      "\n",
      "\n",
      "Vocabulary:\n",
      "['bag of' 'basic technique' 'bow representation' 'can create' 'create bow'\n",
      " 'example of' 'in nlp' 'is basic' 'is simple' 'nlp bag' 'of bow'\n",
      " 'of words' 'representation easily' 'simple example' 'this is' 'words is'\n",
      " 'you can']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample documents\n",
    "documents = [\"This is a simple example of BoW.\",\n",
    "             \"In NLP, Bag of Words is a basic technique.\",\n",
    "             \"You can create a BoW representation easily.\"]\n",
    "\n",
    "# Initialize the CountVectorizer with bigrams\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
    "\n",
    "# Fit and transform the documents\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to a dense array for readability\n",
    "bow_array = X.toarray()\n",
    "\n",
    "# Get the vocabulary\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"BoW Representation with Bigrams:\")\n",
    "print(bow_array)\n",
    "print('\\n')\n",
    "print(\"Vocabulary:\")\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By setting `ngram_range=(2, 2)`, we create a BoW representation of word pairs (bigrams)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. BoW with TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "\n",
    "Combining BoW with TF-IDF can help improve the representation by considering the importance of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Representation:\n",
      "[[0.         0.         0.34949812 0.         0.         0.\n",
      "  0.45954803 0.         0.34949812 0.         0.34949812 0.\n",
      "  0.45954803 0.         0.45954803 0.         0.        ]\n",
      " [0.37380112 0.37380112 0.         0.         0.         0.\n",
      "  0.         0.37380112 0.28428538 0.37380112 0.28428538 0.\n",
      "  0.         0.37380112 0.         0.37380112 0.        ]\n",
      " [0.         0.         0.32200242 0.42339448 0.42339448 0.42339448\n",
      "  0.         0.         0.         0.         0.         0.42339448\n",
      "  0.         0.         0.         0.         0.42339448]]\n",
      "\n",
      "\n",
      "Vocabulary:\n",
      "['bag' 'basic' 'bow' 'can' 'create' 'easily' 'example' 'in' 'is' 'nlp'\n",
      " 'of' 'representation' 'simple' 'technique' 'this' 'words' 'you']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample documents\n",
    "documents = [\"This is a simple example of BoW.\",\n",
    "             \"In NLP, Bag of Words is a basic technique.\",\n",
    "             \"You can create a BoW representation easily.\"]\n",
    "\n",
    "# Initialize the TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the documents\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Convert to a dense array for readability\n",
    "tfidf_array = X.toarray()\n",
    "\n",
    "# Get the vocabulary\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "print(\"TF-IDF Representation:\")\n",
    "print(tfidf_array)\n",
    "print('\\n')\n",
    "print(\"Vocabulary:\")\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use `TfidfVectorizer` to create a BoW representation with TF-IDF scores.\n",
    "\n",
    "These intermediate examples show how to enhance BoW by tokenization, bigrams, and TF-IDF, making it more powerful for various NLP tasks. Explore these techniques further and consider how to apply them to your specific NLP projects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
