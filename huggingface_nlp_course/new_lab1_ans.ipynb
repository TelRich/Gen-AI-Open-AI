{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 1 Notebook\n",
    "\n",
    "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets evaluate transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. \n",
    "What are the sentiment labels and their associated confidence scores provided by the sentiment analysis pipeline for the following text samples:\n",
    "\n",
    "* 'The new restaurant in town exceeded all my expectations, I loved it!'\n",
    "* 'This movie is incredibly captivating and heartwarming.'\n",
    "\n",
    "Please provide the sentiment labels and their respective confidence scores for each text sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the sentiment analysis pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Different text samples for sentiment analysis\n",
    "different_text_samples = [\n",
    "    \"The new restaurant in town exceeded all my expectations, I loved it!\",\n",
    "    \"This movie is incredibly captivating and heartwarming.\",\n",
    "]\n",
    "\n",
    "# Perform sentiment analysis on the new text samples\n",
    "different_sentiment_results = classifier(different_text_samples)\n",
    "\n",
    "print(different_sentiment_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. \n",
    "What are the scores, rounded to four decimal places, assigned to the candidate labels when using zero-shot classification with the given text: 'The latest scientific research suggests a breakthrough in renewable energy sources.'? The candidate labels are 'technology', 'environment', and 'health'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "# Text to classify\n",
    "text_to_classify = \"The latest scientific research suggests a breakthrough in renewable energy sources.\"\n",
    "\n",
    "# Candidate labels/categories\n",
    "candidate_labels = [\"technology\", \"environment\", \"health\"]\n",
    "\n",
    "# Perform zero-shot classification\n",
    "result = classifier(text_to_classify, candidate_labels)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. \n",
    "What are three different texts generated by a text generation model using the prompt 'Exploring the vast universe beyond our solar system'? The model used is based on the distilgpt2 architecture, with a maximum length of 30 tokens for each generated sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Create a text generation pipeline using the distilgpt2 model\n",
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "\n",
    "# Change the context for text generation\n",
    "generated_text = generator(\n",
    "    \"Exploring the vast universe beyond our solar system\",\n",
    "    max_length=30,\n",
    "    num_return_sequences=3,\n",
    ")\n",
    "\n",
    "# Print the generated texts\n",
    "for sequence in generated_text:\n",
    "    print(sequence['generated_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\n",
    "\n",
    "What are three different words suggested to fill in the mask in the sentence 'Discovering new <mask> is an exciting adventure.'? The model used provides the top three predicted words to fill the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Create a pipeline for masked text filling\n",
    "unmasker = pipeline(\"fill-mask\")\n",
    "\n",
    "# Provide a different context for masked text filling\n",
    "filled_masks = unmasker(\"Discovering new <mask> is an exciting adventure.\", top_k=3)\n",
    "\n",
    "# Display the filled mask results\n",
    "for result in filled_masks:\n",
    "    print(result['sequence'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\n",
    "\n",
    "What are the identified named entities, their corresponding entity types, and the associated confidence scores in the sentence _'The company SpaceX, founded by Elon Musk, is known for its ambitious projects.'_ according to the Named Entity Recognition (NER) model?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Create a Named Entity Recognition pipeline\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "\n",
    "# Analyze entities in the text\n",
    "entities = ner(\"The company SpaceX, founded by Elon Musk, is known for its ambitious projects.\")\n",
    "\n",
    "# Print identified entities\n",
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['entity_group']}, Text: {entity['word']}, Score: {entity['score']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.\n",
    "\n",
    "What information does the question-answering model provide when asked, _'What is the capital of France?'_ within the context of _'Paris is the capital city of France, known for its art, fashion, and culture.'?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Create a question-answering pipeline\n",
    "question_answerer = pipeline(\"question-answering\")\n",
    "\n",
    "# Provide a different context and ask a question\n",
    "answer = question_answerer(\n",
    "    question=\"What is the capital of France?\",\n",
    "    context=\"Paris is the capital city of France, known for its art, fashion, and culture.\",\n",
    ")\n",
    "\n",
    "# Print the answer\n",
    "print(answer['answer'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.\n",
    "\n",
    "What is the summarization provided by the summarization pipeline for the following text:\n",
    "\n",
    "'Artificial intelligence (AI) has been rapidly evolving in recent years, impacting various industries and sectors worldwide. Its applications span from healthcare to finance, revolutionizing how tasks are performed and problems are solved. However, the rapid advancement of AI also raises ethical concerns regarding privacy, bias, and job displacement. As AI technology continues to develop, it becomes crucial to address these ethical implications and ensure responsible use. While AI offers immense potential for innovation and efficiency, it must be guided by ethical frameworks to mitigate risks and maximize benefits.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the summarization pipeline\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "# Provide a different text for summarization\n",
    "summary = summarizer(\n",
    "    \"\"\"\n",
    "   Artificial intelligence (AI) has been rapidly evolving in recent years, impacting various industries and sectors worldwide. \n",
    "    Its applications span from healthcare to finance, revolutionizing how tasks are performed and problems are solved. \n",
    "    However, the rapid advancement of AI also raises ethical concerns regarding privacy, bias, and job displacement. \n",
    "    As AI technology continues to develop, it becomes crucial to address these ethical implications and ensure responsible use. \n",
    "    While AI offers immense potential for innovation and efficiency, it must be guided by ethical frameworks to mitigate risks and maximize benefits.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Print the generated summary\n",
    "print(summary[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.\n",
    "\n",
    "What is the English translation of the following French sentence using the **Helsinki-NLP/opus-mt-fr-en** translation model: _'La ville de Paris est célèbre pour sa tour Eiffel.'?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Translation pipeline for French to English\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "\n",
    "# Translate a French sentence to English\n",
    "translated_text = translator(\"La ville de Paris est célèbre pour sa tour Eiffel.\")\n",
    "\n",
    "# Display the translated text\n",
    "print(translated_text[0]['translation_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. \n",
    "Why might the following code not work when using the fill-mask pipeline from the Transformers library?\n",
    "\n",
    "```python\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the fill-mask pipeline\n",
    "unmasker = pipeline(\"fill-mask\")\n",
    "\n",
    "# Text with a mask to fill\n",
    "text_with_mask = \"Exploring the depths of  is an exciting adventure.\"\n",
    "\n",
    "# Perform the masked language modeling\n",
    "filled_mask = unmasker(text_with_mask, top_k=3)\n",
    "```\n",
    "\n",
    "### ANSWER\n",
    "\"a) The text provided for filling the mask does not contain a valid mask token (\"\\<mask\\>\").\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.\n",
    "\n",
    " What is the result of the below code?\n",
    " \n",
    "```python\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the Named Entity Recognition (NER) pipeline\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "\n",
    "# Text for named entity recognition\n",
    "new_text_to_analyze = \"During the space mission, Neil Armstrong landed on the moon in 1969.\"\n",
    "\n",
    "# Perform Named Entity Recognition (NER)\n",
    "new_ner_result = ner(new_text_to_analyze)\n",
    "\n",
    "print(new_ner_result)\n",
    "```\n",
    "\n",
    "### ANSWER \n",
    "\" C) {'entity_group': 'PER', 'score': 0.99813056, 'word': 'Neil Armstrong', 'start': 26, 'end': 40}\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
