{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 1 Notebook\n",
    "\n",
    "Install the Transformers, Datasets, and Evaluate libraries to run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets evaluate transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. \n",
    "What are the sentiment labels and their associated confidence scores provided by the sentiment analysis pipeline for the following text samples:\n",
    "\n",
    "* 'The new restaurant in town exceeded all my expectations, I loved it!'\n",
    "* 'This movie is incredibly captivating and heartwarming.'\n",
    "\n",
    "Please provide the sentiment labels and their respective confidence scores for each text sample.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998594522476196}, {'label': 'POSITIVE', 'score': 0.9998866319656372}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the sentiment analysis pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Different text samples for sentiment analysis\n",
    "different_text_samples = [\n",
    "    \"The new restaurant in town exceeded all my expectations, I loved it!\",\n",
    "    \"This movie is incredibly captivating and heartwarming.\",\n",
    "]\n",
    "\n",
    "# Perform sentiment analysis on the new text samples\n",
    "different_sentiment_results = classifier(different_text_samples)\n",
    "\n",
    "print(different_sentiment_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. \n",
    "What are the scores, rounded to four decimal places, assigned to the candidate labels when using zero-shot classification with the given text: 'The latest scientific research suggests a breakthrough in renewable energy sources.'? The candidate labels are 'technology', 'environment', and 'health'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'The latest scientific research suggests a breakthrough in renewable energy sources.', 'labels': ['technology', 'environment', 'health'], 'scores': [0.8185637593269348, 0.16402819752693176, 0.017408087849617004]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the zero-shot classification pipeline\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "# Text to classify\n",
    "text_to_classify = \"The latest scientific research suggests a breakthrough in renewable energy sources.\"\n",
    "\n",
    "# Candidate labels/categories\n",
    "candidate_labels = [\"technology\", \"environment\", \"health\"]\n",
    "\n",
    "# Perform zero-shot classification\n",
    "result = classifier(text_to_classify, candidate_labels)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. \n",
    "What are three different texts generated by a text generation model using the prompt 'Exploring the vast universe beyond our solar system'? The model used is based on the distilgpt2 architecture, with a maximum length of 30 tokens for each generated sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b3fb2c7bdbf465a88f8e2da367468d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894dfe34e23d4196945196585317ec94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b988a05f84e74316a2aacf30726c364a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9335a622bedc4a7eab77843b6a0b3671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b0c1e6a479446cac1f7ef6c6059dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94fc5d54bb9941c5a8305de219705967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploring the vast universe beyond our solar systemâ€™s orbit to avoid impacting other galaxies. Using the technique of looking at the stars themselves, the\n",
      "Exploring the vast universe beyond our solar system, or even Earth, is the best way to do that. But what if we did not take enough\n",
      "Exploring the vast universe beyond our solar system; creating a universe filled with dark stars of life, and the universe orbiting one another.\n",
      "After the\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Create a text generation pipeline using the distilgpt2 model\n",
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "\n",
    "# Change the context for text generation\n",
    "generated_text = generator(\n",
    "    \"Exploring the vast universe beyond our solar system\",\n",
    "    max_length=30,\n",
    "    num_return_sequences=3,\n",
    ")\n",
    "\n",
    "# Print the generated texts\n",
    "for sequence in generated_text:\n",
    "    print(sequence['generated_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.\n",
    "\n",
    "What are three different words suggested to fill in the mask in the sentence 'Discovering new <mask> is an exciting adventure.'? The model used provides the top three predicted words to fill the mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fd2c26057fb4c7b9a0560e87a8bcf13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231c81ce279c42459ba5ef9b844cdf32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/331M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa33b4f3e1214b20a2f77898e423398b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216cb0cf72784f66bed658f34cf05577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1dceeb011f4a7b8a5564353f657780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discovering new worlds is an exciting adventure.\n",
      "Discovering new planets is an exciting adventure.\n",
      "Discovering new cultures is an exciting adventure.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Create a pipeline for masked text filling\n",
    "unmasker = pipeline(\"fill-mask\")\n",
    "\n",
    "# Provide a different context for masked text filling\n",
    "filled_masks = unmasker(\"Discovering new <mask> is an exciting adventure.\", top_k=3)\n",
    "\n",
    "# Display the filled mask results\n",
    "for result in filled_masks:\n",
    "    print(result['sequence'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.\n",
    "\n",
    "What are the identified named entities, their corresponding entity types, and the associated confidence scores in the sentence _'The company SpaceX, founded by Elon Musk, is known for its ambitious projects.'_ according to the Named Entity Recognition (NER) model?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f6beafe13ba46749822702817b44073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/998 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64173a448424ab3ad6129850d0b5001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdfb771876d743a38b15d97be2106e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f75de5e083f4dee9e3b26eaf1a5e7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/pipelines/token_classification.py:169: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity: ORG, Text: SpaceX, Score: 0.9992449283599854\n",
      "Entity: PER, Text: Elon Musk, Score: 0.9942229986190796\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Create a Named Entity Recognition pipeline\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "\n",
    "# Analyze entities in the text\n",
    "entities = ner(\"The company SpaceX, founded by Elon Musk, is known for its ambitious projects.\")\n",
    "\n",
    "# Print identified entities\n",
    "for entity in entities:\n",
    "    print(f\"Entity: {entity['entity_group']}, Text: {entity['word']}, Score: {entity['score']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.\n",
    "\n",
    "What information does the question-answering model provide when asked, _'What is the capital of France?'_ within the context of _'Paris is the capital city of France, known for its art, fashion, and culture.'?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Create a question-answering pipeline\n",
    "question_answerer = pipeline(\"question-answering\")\n",
    "\n",
    "# Provide a different context and ask a question\n",
    "answer = question_answerer(\n",
    "    question=\"What is the capital of France?\",\n",
    "    context=\"Paris is the capital city of France, known for its art, fashion, and culture.\",\n",
    ")\n",
    "\n",
    "# Print the answer\n",
    "print(answer['answer'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.\n",
    "\n",
    "What is the summarization provided by the summarization pipeline for the following text:\n",
    "\n",
    "'Artificial intelligence (AI) has been rapidly evolving in recent years, impacting various industries and sectors worldwide. Its applications span from healthcare to finance, revolutionizing how tasks are performed and problems are solved. However, the rapid advancement of AI also raises ethical concerns regarding privacy, bias, and job displacement. As AI technology continues to develop, it becomes crucial to address these ethical implications and ensure responsible use. While AI offers immense potential for innovation and efficiency, it must be guided by ethical frameworks to mitigate risks and maximize benefits.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43cf762fb0d14224aff2f2295b89f147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0542c7cefd7b45c58769fa08d702a9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eb1c90e0401493c96e1ae622ca5a151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57dce0375d5e423dad59b185a94337bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0a497d80dc4a35aba18cbe9aa47cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 142, but your input_length is only 134. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=67)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Artificial intelligence (AI) has been rapidly evolving in recent years, impacting various industries and sectors worldwide . Its applications span from healthcare to finance, revolutionizing how tasks are performed and problems are solved . However, the rapid advancement of AI also raises ethical concerns regarding privacy, bias, and job displacement .\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the summarization pipeline\n",
    "summarizer = pipeline(\"summarization\")\n",
    "\n",
    "# Provide a different text for summarization\n",
    "summary = summarizer(\n",
    "    \"\"\"\n",
    "   Artificial intelligence (AI) has been rapidly evolving in recent years, impacting various industries and sectors worldwide. \n",
    "    Its applications span from healthcare to finance, revolutionizing how tasks are performed and problems are solved. \n",
    "    However, the rapid advancement of AI also raises ethical concerns regarding privacy, bias, and job displacement. \n",
    "    As AI technology continues to develop, it becomes crucial to address these ethical implications and ensure responsible use. \n",
    "    While AI offers immense potential for innovation and efficiency, it must be guided by ethical frameworks to mitigate risks and maximize benefits.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Print the generated summary\n",
    "print(summary[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.\n",
    "\n",
    "What is the English translation of the following French sentence using the **Helsinki-NLP/opus-mt-fr-en** translation model: _'La ville de Paris est cÃ©lÃ¨bre pour sa tour Eiffel.'?_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc74354b118d405f8b8b16e8d9440472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ee4b4966c74d1f81e17e08a0521b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/301M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc55efcdff3040999dccb0a9c81949bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1490295379d84cf8bb60bc80f1eb1a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82494fbe205645f58b33761b5ba2db9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading source.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0eae563f2c410a9d4e788946bc02b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading target.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f12d36f28240cfbc9f93eabac78ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The city of Paris is famous for its Eiffel Tower.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Translation pipeline for French to English\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-fr-en\")\n",
    "\n",
    "# Translate a French sentence to English\n",
    "translated_text = translator(\"La ville de Paris est cÃ©lÃ¨bre pour sa tour Eiffel.\")\n",
    "\n",
    "# Display the translated text\n",
    "print(translated_text[0]['translation_text'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. \n",
    "Why might the following code not work when using the fill-mask pipeline from the Transformers library?\n",
    "\n",
    "```python\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the fill-mask pipeline\n",
    "unmasker = pipeline(\"fill-mask\")\n",
    "\n",
    "# Text with a mask to fill\n",
    "text_with_mask = \"Exploring the depths of  is an exciting adventure.\"\n",
    "\n",
    "# Perform the masked language modeling\n",
    "filled_mask = unmasker(text_with_mask, top_k=3)\n",
    "```\n",
    "\n",
    "### ANSWER\n",
    "\"a) The text provided for filling the mask does not contain a valid mask token (\"\\<mask\\>\").\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.\n",
    "\n",
    " What is the result of the below code?\n",
    " \n",
    "```python\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the Named Entity Recognition (NER) pipeline\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "\n",
    "# Text for named entity recognition\n",
    "new_text_to_analyze = \"During the space mission, Neil Armstrong landed on the moon in 1969.\"\n",
    "\n",
    "# Perform Named Entity Recognition (NER)\n",
    "new_ner_result = ner(new_text_to_analyze)\n",
    "\n",
    "print(new_ner_result)\n",
    "```\n",
    "\n",
    "### ANSWER \n",
    "\" C) {'entity_group': 'PER', 'score': 0.99813056, 'word': 'Neil Armstrong', 'start': 26, 'end': 40}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
