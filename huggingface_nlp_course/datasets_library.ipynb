{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Dataset Library**\n",
    "\n",
    "In this chapter, you'll delve deeper into the capabilities of the ðŸ¤— Datasets library. Here are some of the key questions you'll explore:\n",
    "\n",
    "1. How to handle datasets not available on the Hugging Face Hub?\n",
    "2. Techniques for slicing, dicing, and working with datasets, including using Pandas.\n",
    "3. Handling large datasets that might overwhelm your system's RAM.\n",
    "4. Understanding concepts like memory mapping and Apache Arrow.\n",
    "5. Creating custom datasets and contributing them to the Hugging Face Hub.\n",
    "\n",
    "Let's embark on this journey to enhance your understanding of ðŸ¤— Datasets!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What should I do if my dataset isn't available on the Hugging Face Hub?\n",
    "\n",
    "You've learned how to utilize the Hugging Face Hub to fetch datasets, but there will be instances where you need to work with data stored locally on your laptop or on a remote server. In this section, we'll explore how ðŸ¤— Datasets can be employed to load datasets that aren't accessible on the Hugging Face Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with local and remote datasets\n",
    "\n",
    "ðŸ¤— Datasets simplifies the loading of local and remote datasets by providing loading scripts for various common data formats. Here are examples of loading scripts for different data formats:\n",
    "\n",
    "- CSV & TSV: `load_dataset(\"csv\", data_files=\"my_file.csv\")`\n",
    "- Text files: `load_dataset(\"text\", data_files=\"my_file.txt\")`\n",
    "- JSON & JSON Lines: `load_dataset(\"json\", data_files=\"my_file.jsonl\")`\n",
    "- Pickled DataFrames: `load_dataset(\"pandas\", data_files=\"my_dataframe.pkl\")`\n",
    "\n",
    "The above illustrates that for each data format, specifying the type of loading script in the `load_dataset()` function is sufficient. Additionally, the `data_files` argument is used to provide the path to one or more files. Let's begin by loading a dataset from local files, and subsequently, we'll explore how to achieve the same with remote files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a local dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-train.json.gz\n",
    "!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-test.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will download two compressed files called SQuAD_it-train.json.gz and SQuAD_it-test.json.gz, which we can decompress with the Linux gzip command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
